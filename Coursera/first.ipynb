{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c9b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Step 1: Data\n",
    "X = torch.tensor([[1.0], [2.0], [3.0], [4.0], [5.0]])  # hours studied\n",
    "y = torch.tensor([[0.0], [0.0], [0.0], [1.0], [1.0]])  # passed (0 or 1)\n",
    "\n",
    "# Step 2: Logistic Regression Model (1 input â†’ 1 output)\n",
    "class LogisticModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)  # simple line: y = wx + b\n",
    "        self.sigmoid = nn.Sigmoid()   # convert output to probability (0 to 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))  # prediction between 0 and 1\n",
    "\n",
    "model = LogisticModel()\n",
    "\n",
    "# Step 3: Loss Function (Binary Cross Entropy)\n",
    "loss_fn = nn.BCELoss()  # because our output is 0 or 1\n",
    "\n",
    "# Step 4: Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)  # update weights\n",
    "\n",
    "# Step 5: Training Loop\n",
    "for epoch in range(1000):\n",
    "    # Forward pass (make prediction)\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print every 100 steps\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8361f130",
   "metadata": {},
   "source": [
    "#ðŸ§¾ Whatâ€™s happening here:\n",
    "Model predicts a value between 0 and 1 (probability of passing)\n",
    "\n",
    "Cross-entropy compares this predicted probability with the actual label (0 or 1)\n",
    "\n",
    "If the model is confidently wrong (like predicts 0.9 when actual is 0), it gets a big loss.\n",
    "\n",
    "The optimizer uses this loss to fix the model's weights and improve future predictions.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
